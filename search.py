import logging
logger = logging.getLogger(__name__)
"""
Gestionnaire des fonctions de recherche et d'indexation
"""

import logging
import os
import hashlib
from datetime import datetime
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes

class SearchHandler:
    """Gestionnaire des fonctions de recherche"""
    
    def __init__(self, db, translations):
        self.db = db
        self.translations = translations
        self.logger = logging.getLogger(__name__)
        self.supported_formats = ['.pdf', '.docx', '.txt', '.md', '.doc']
        self.max_file_size = 50 * 1024 * 1024  # 50MB
    
    async def search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Commande /search - Recherche dans les documents index√©s"""
        if not context.args:
            await update.message.reply_text(
                "üîç **Recherche de documents**\n\n"
                "Usage: `/search <terme de recherche>`\n\n"
                "Exemples:\n"
                "‚Ä¢ `/search contrat` - Cherche le mot 'contrat'\n"
                "‚Ä¢ `/search \"phrase exacte\"` - Recherche de phrase\n"
                "‚Ä¢ `/search tag:important` - Recherche par tag\n\n"
                "üìä Statistiques:\n"
                f"‚Ä¢ Documents index√©s: {self.db.get_indexed_documents_count()}\n"
                f"‚Ä¢ Recherches ce mois: {self.db.get_monthly_search_count()}",
                parse_mode='Markdown'
            )
            return
        
        query = " ".join(context.args)
        user_id = update.effective_user.id
        
        # V√©rifier les limites pour les utilisateurs non-premium
        if not self.db.is_premium_user(user_id):
            daily_searches = self.db.get_daily_search_count(user_id)
            if daily_searches >= 10:
                await update.message.reply_text(
                    "üîí **Limite de recherche atteinte**\n\n"
                    "Utilisateurs gratuits: 10 recherches/jour\n"
                    "Vous avez utilis√© toutes vos recherches aujourd'hui.\n\n"
                    "üí° Passez Premium pour des recherches illimit√©es!"
                )
                return
        
        # Effectuer la recherche
        results = await self.perform_search(query, user_id)
        
        if not results:
            await update.message.reply_text(
                f"üîç **Aucun r√©sultat trouv√©**\n\n"
                f"Requ√™te: `{query}`\n\n"
                "üí° Conseils:\n"
                "‚Ä¢ V√©rifiez l'orthographe\n"
                "‚Ä¢ Essayez des termes plus g√©n√©raux\n"
                "‚Ä¢ Utilisez des synonymes\n"
                "‚Ä¢ Indexez plus de documents avec /index",
                parse_mode='Markdown'
            )
            return
        
        # Afficher les r√©sultats
        await self.display_search_results(update, query, results)
        
        # Enregistrer la recherche
        self.db.log_search(user_id, query, len(results))
    
    async def index_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Commande /index - Gestion de l'indexation"""
        user_id = update.effective_user.id
        
        text = """üìö **Indexation de Documents**

üîç **Formats support√©s:**
‚Ä¢ PDF (.pdf)
‚Ä¢ Word (.docx, .doc)
‚Ä¢ Texte (.txt, .md)

üìä **Vos statistiques:**
‚Ä¢ Documents index√©s: {indexed_count}
‚Ä¢ Taille totale: {total_size} MB
‚Ä¢ Derni√®re indexation: {last_indexed}

üí° **Comment indexer:**
1. Envoyez un document dans ce chat
2. Le bot l'analysera automatiquement
3. Le contenu sera indexable via /search""".format(
            indexed_count=self.db.get_user_indexed_count(user_id),
            total_size=round(self.db.get_user_storage_size(user_id) / (1024*1024), 2),
            last_indexed=self.db.get_last_indexed_date(user_id) or "Jamais"
        )
        
        keyboard = [
            [InlineKeyboardButton("üìÇ Mes documents", callback_data="search_my_docs")],
            [InlineKeyboardButton("üóëÔ∏è Supprimer documents", callback_data="search_delete_docs")],
            [InlineKeyboardButton("üìä Statistiques d√©taill√©es", callback_data="search_stats")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        await update.message.reply_text(text, reply_markup=reply_markup, parse_mode='Markdown')
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Traite les documents envoy√©s pour indexation"""
        document = update.message.document
        user_id = update.effective_user.id
        
        # V√©rifications de base
        if not document:
            return
        
        if document.file_size > self.max_file_size:
            await update.message.reply_text(
                f"‚ùå **Fichier trop volumineux**\n\n"
                f"Taille: {round(document.file_size / (1024*1024), 2)} MB\n"
                f"Limite: {self.max_file_size // (1024*1024)} MB\n\n"
                f"üí° Compressez le fichier ou passez Premium pour une limite plus √©lev√©e."
            )
            return
        
        # V√©rifier le format
        file_extension = os.path.splitext(document.file_name or "")[1].lower()
        if file_extension not in self.supported_formats:
            await update.message.reply_text(
                f"‚ùå **Format non support√©**\n\n"
                f"Fichier: {document.file_name}\n"
                f"Format: {file_extension}\n\n"
                f"üìÑ Formats support√©s: {', '.join(self.supported_formats)}"
            )
            return
        
        # V√©rifier les limites de stockage
        if not self.db.is_premium_user(user_id):
            user_storage = self.db.get_user_storage_size(user_id)
            storage_limit = 100 * 1024 * 1024  # 100MB pour utilisateurs gratuits
            
            if user_storage + document.file_size > storage_limit:
                await update.message.reply_text(
                    f"üíæ **Limite de stockage atteinte**\n\n"
                    f"Utilis√©: {round(user_storage / (1024*1024), 2)} MB\n"
                    f"Nouveau fichier: {round(document.file_size / (1024*1024), 2)} MB\n"
                    f"Limite gratuite: {storage_limit // (1024*1024)} MB\n\n"
                    f"üóëÔ∏è Supprimez des documents ou passez Premium!"
                )
                return
        
        # T√©l√©charger et indexer le document
        try:
            processing_msg = await update.message.reply_text(
                "üîÑ **Traitement en cours...**\n\n"
                f"üìÑ Fichier: {document.file_name}\n"
                f"üìä Taille: {round(document.file_size / 1024, 2)} KB\n\n"
                "‚è≥ T√©l√©chargement et analyse..."
            )
            
            # T√©l√©charger le fichier
            file = await context.bot.get_file(document.file_id)
            file_path = f"uploads/{user_id}_{document.file_id}_{document.file_name}"
            
            # Cr√©er le dossier uploads s'il n'existe pas
            os.makedirs("uploads", exist_ok=True)
            
            await file.download_to_drive(file_path)
            
            # Extraire le texte selon le format
            extracted_text = await self.extract_text_from_file(file_path, file_extension)
            
            if not extracted_text:
                await processing_msg.edit_text(
                    "‚ùå **Erreur d'extraction**\n\n"
                    "Impossible d'extraire le texte de ce document.\n"
                    "Le fichier pourrait √™tre corrompu ou prot√©g√©."
                )
                return
            
            # Indexer le document
            doc_id = await self.index_document(
                user_id=user_id,
                file_name=document.file_name,
                file_size=document.file_size,
                file_path=file_path,
                content=extracted_text,
                file_type=file_extension
            )
            
            # Analyser le contenu
            word_count = len(extracted_text.split())
            keywords = self.extract_keywords(extracted_text)
            
            await processing_msg.edit_text(
                f"‚úÖ **Document index√© avec succ√®s!**\n\n"
                f"üìÑ Nom: {document.file_name}\n"
                f"üî§ Mots extraits: {word_count:,}\n"
                f"üè∑Ô∏è Mots-cl√©s: {', '.join(keywords[:5])}\n"
                f"üÜî ID: `{doc_id}`\n\n"
                f"üîç Utilisez `/search` pour rechercher dans ce document!",
                parse_mode='Markdown'
            )
            
            # Nettoyer le fichier temporaire
            try:
                os.remove(file_path)
            except:
                pass
                
        except Exception as e:
            self.logger.error(f"Erreur lors de l'indexation: {e}")
            await update.message.reply_text(
                "‚ùå **Erreur lors du traitement**\n\n"
                "Une erreur s'est produite lors de l'indexation.\n"
                "Veuillez r√©essayer ou contacter le support."
            )
    
    async def extract_text_from_file(self, file_path, file_extension):
        """Extrait le texte d'un fichier selon son format"""
        try:
            if file_extension in ['.txt', '.md']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            
            elif file_extension == '.pdf':
                # Simulation d'extraction PDF (n√©cessiterait PyPDF2 ou pdfplumber)
                return f"Contenu simul√© du PDF: {os.path.basename(file_path)}\n" + \
                       "Ceci est un contenu d'exemple pour la d√©monstration.\n" + \
                       "Dans un environnement r√©el, le contenu serait extrait du PDF."
            
            elif file_extension in ['.docx', '.doc']:
                # Simulation d'extraction Word (n√©cessiterait python-docx)
                return f"Contenu simul√© du document Word: {os.path.basename(file_path)}\n" + \
                       "Texte d'exemple extrait du document Word.\n" + \
                       "En production, le vrai contenu serait analys√©."
            
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"Erreur extraction texte: {e}")
            return None
    
    async def index_document(self, user_id, file_name, file_size, file_path, content, file_type):
        """Indexe un document dans la base de donn√©es"""
        # G√©n√©rer un hash unique pour le document
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        # V√©rifier si le document existe d√©j√†
        existing_doc = self.db.get_document_by_hash(user_id, content_hash)
        if existing_doc:
            return existing_doc['id']
        
        # Cr√©er l'entr√©e dans la base de donn√©es
        doc_data = {
            'user_id': user_id,
            'file_name': file_name,
            'file_size': file_size,
            'file_type': file_type,
            'content': content,
            'content_hash': content_hash,
            'keywords': ','.join(self.extract_keywords(content)),
            'indexed_at': datetime.now(),
            'word_count': len(content.split())
        }
        
        return self.db.create_indexed_document(doc_data)
    
    def extract_keywords(self, text):
        """Extrait les mots-cl√©s d'un texte"""
        # Liste de mots vides en fran√ßais et anglais
        stop_words = {
            'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', 'mais',
            'donc', 'car', 'que', 'qui', 'quoi', 'dont', 'o√π', 'ce', 'cette',
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been'
        }
        
        # Nettoyer et diviser le texte
        words = text.lower().split()
        cleaned_words = []
        
        for word in words:
            # Enlever la ponctuation
            word = ''.join(char for char in word if char.isalnum())
            
            # Filtrer les mots courts et les mots vides
            if len(word) > 3 and word not in stop_words:
                cleaned_words.append(word)
        
        # Compter les occurrences
        word_count = {}
        for word in cleaned_words:
            word_count[word] = word_count.get(word, 0) + 1
        
        # Retourner les mots les plus fr√©quents
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words[:20]]
    
    async def perform_search(self, query, user_id):
        """Effectue une recherche dans les documents index√©s"""
        # Analyser la requ√™te
        search_terms = self.parse_search_query(query)
        
        # Rechercher dans la base de donn√©es
        results = self.db.search_documents(user_id, search_terms)
        
        # Trier les r√©sultats par pertinence
        scored_results = []
        for result in results:
            score = self.calculate_relevance_score(result, search_terms)
            scored_results.append((score, result))
        
        # Trier par score d√©croissant
        scored_results.sort(key=lambda x: x[0], reverse=True)
        
        return [result for score, result in scored_results[:20]]  # Top 20 r√©sultats
    
    def parse_search_query(self, query):
        """Analyse une requ√™te de recherche"""
        terms = {
            'words': [],
            'phrases': [],
            'tags': [],
            'exclude': []
        }
        
        # Recherche de phrases entre guillemets
        import re
        phrases = re.findall(r'"([^"]*)"', query)
        terms['phrases'] = phrases
        
        # Enlever les phrases de la requ√™te
        query_without_phrases = re.sub(r'"[^"]*"', '', query)
        
        # Recherche de tags
        tags = re.findall(r'tag:(\w+)', query_without_phrases)
        terms['tags'] = tags
        
        # Enlever les tags de la requ√™te
        query_without_tags = re.sub(r'tag:\w+', '', query_without_phrases)
        
        # Recherche de mots √† exclure
        exclude_words = re.findall(r'-(\w+)', query_without_tags)
        terms['exclude'] = exclude_words
        
        # Enlever les mots exclus
        query_clean = re.sub(r'-\w+', '', query_without_tags)
        
        # Mots restants
        words = [word.strip() for word in query_clean.split() if word.strip()]
        terms['words'] = words
        
        return terms
    
    def calculate_relevance_score(self, document, search_terms):
        """Calcule un score de pertinence pour un document"""
        score = 0
        content = document.get('content', '').lower()
        title = document.get('file_name', '').lower()
        keywords = document.get('keywords', '').lower()
        
        # Score pour les mots dans le titre (poids plus √©lev√©)
        for word in search_terms['words']:
            if word.lower() in title:
                score += 10
            if word.lower() in content:
                score += content.count(word.lower())
            if word.lower() in keywords:
                score += 5
        
        # Score pour les phrases exactes
        for phrase in search_terms['phrases']:
            if phrase.lower() in content:
                score += 20
            if phrase.lower() in title:
                score += 30
        
        # Score pour les tags
        for tag in search_terms['tags']:
            if tag.lower() in keywords:
                score += 15
        
        # P√©nalit√© pour les mots exclus
        for exclude_word in search_terms['exclude']:
            if exclude_word.lower() in content:
                score -= 10
        
        return max(0, score)
    
    async def display_search_results(self, update, query, results):
        """Affiche les r√©sultats de recherche"""
        text = f"üîç **R√©sultats de recherche**\n\n"
        text += f"Requ√™te: `{query}`\n"
        text += f"R√©sultats: {len(results)} document(s)\n\n"
        
        for i, result in enumerate(results[:10], 1):
            # Cr√©er un extrait du contenu
            content = result.get('content', '')
            extract = self.create_excerpt(content, query)
            
            text += f"**{i}. {result['file_name']}**\n"
            text += f"   üìÑ Type: {result['file_type']}\n"
            text += f"   üìÖ Index√©: {result['indexed_at']}\n"
            text += f"   üìù Extrait: _{extract}_\n\n"
        
        if len(results) > 10:
            text += f"... et {len(results) - 10} autres r√©sultats\n\n"
        
        text += "üí° Utilisez `/search \"phrase exacte\"` pour une recherche plus pr√©cise"
        
        keyboard = [
            [InlineKeyboardButton("üìä Filtrer r√©sultats", callback_data=f"search_filter_{query}")],
            [InlineKeyboardButton("üíæ Exporter r√©sultats", callback_data=f"search_export_{query}")],
            [InlineKeyboardButton("üîç Nouvelle recherche", callback_data="search_new")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        # D√©couper le message si trop long
        if len(text) > 4000:
            parts = [text[i:i+4000] for i in range(0, len(text), 4000)]
            for i, part in enumerate(parts):
                if i == len(parts) - 1:  # Dernier message avec les boutons
                    await update.message.reply_text(part, reply_markup=reply_markup, parse_mode='Markdown')
                else:
                    await update.message.reply_text(part, parse_mode='Markdown')
        else:
            await update.message.reply_text(text, reply_markup=reply_markup, parse_mode='Markdown')
    
    def create_excerpt(self, content, query, max_length=100):
        """Cr√©e un extrait de texte autour des termes de recherche"""
        if not content:
            return "Aucun contenu disponible"
        
        # Trouver la premi√®re occurrence d'un terme de la requ√™te
        query_words = query.lower().split()
        content_lower = content.lower()
        
        best_position = 0
        for word in query_words:
            pos = content_lower.find(word)
            if pos != -1:
                best_position = pos
                break
        
        # Extraire autour de cette position
        start = max(0, best_position - max_length // 2)
        end = min(len(content), start + max_length)
        excerpt = content[start:end]
        
        # Ajouter "..." si tronqu√©
        if start > 0:
            excerpt = "..." + excerpt
        if end < len(content):
            excerpt = excerpt + "..."
        
        return excerpt.strip()
    
    async def handle_callback(self, update, context):
        """Gestionnaire des callbacks de recherche"""
        query = update.callback_query
        data = query.data
        
        await query.answer()
        
        if data == "search_my_docs":
            await self.show_user_documents(query)
        elif data == "search_delete_docs":
            await self.show_delete_options(query)
        elif data == "search_stats":
            await self.show_search_statistics(query)
        elif data.startswith("search_filter_"):
            query_text = data.replace("search_filter_", "")
            await self.show_filter_options(query, query_text)
        elif data.startswith("search_export_"):
            query_text = data.replace("search_export_", "")
            await self.export_search_results(query, query_text)
        elif data == "search_new":
            await self.prompt_new_search(query)
    
    async def show_user_documents(self, query):
        """Affiche les documents de l'utilisateur"""
        user_id = query.from_user.id
        documents = self.db.get_user_documents(user_id, limit=20)
        
        if not documents:
            text = "üìÇ **Vos Documents**\n\nAucun document index√©."
        else:
            text = f"üìÇ **Vos Documents** ({len(documents)})\n\n"
            
            for i, doc in enumerate(documents[:15], 1):
                size_mb = round(doc['file_size'] / (1024*1024), 2)
                text += f"**{i}. {doc['file_name']}**\n"
                text += f"   üìä {size_mb} MB | {doc['word_count']} mots\n"
                text += f"   üìÖ {doc['indexed_at']}\n\n"
        
        keyboard = [
            [InlineKeyboardButton("üóëÔ∏è Supprimer documents", callback_data="search_delete_docs")],
            [InlineKeyboardButton("üîô Retour", callback_data="search_back")]
        ]
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(text, reply_markup=reply_markup, parse_mode='Markdown')
    
    async def show_search_statistics(self, query):
        """Affiche les statistiques de recherche"""
        user_id = query.from_user.id
        stats = self.db.get_user_search_stats(user_id)
        
        text = f"""üìä **Statistiques de Recherche**

üìà **Utilisation:**
‚Ä¢ Recherches totales: {stats['total_searches']}
‚Ä¢ Recherches ce mois: {stats['monthly_searches']}
‚Ä¢ Moyenne/jour: {stats['daily_average']}

üìö **Documents:**
‚Ä¢ Total index√©s: {stats['total_documents']}
‚Ä¢ Taille totale: {round(stats['total_size'] / (1024*1024), 2)} MB
‚Ä¢ Mots index√©s: {stats['total_words']:,}

üîç **Recherches populaires:**
{self.format_popular_searches(stats['popular_searches'])}

‚≠ê **Efficacit√©:**
‚Ä¢ Taux de succ√®s: {stats['success_rate']}%
‚Ä¢ Temps moyen: {stats['avg_response_time']}ms"""
        
        keyboard = [[InlineKeyboardButton("üîô Retour", callback_data="search_back")]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await query.edit_message_text(text, reply_markup=reply_markup, parse_mode='Markdown')
    
    def format_popular_searches(self, searches):
        """Formate les recherches populaires"""
        if not searches:
            return "Aucune recherche r√©cente"
        
        result = ""
        for i, search in enumerate(searches[:5], 1):
            result += f"{i}. `{search['query']}` ({search['count']} fois)\n"
        
        return result
